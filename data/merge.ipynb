{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, if your code is interrupted, you can copy the output and made it a .txt file. Then you can merge your .txt file and .json file with this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def merge_txt_cases_to_json(txt_path, json_path, output_path):\n",
    "    # Step 1: Load Json\n",
    "    with open(json_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    existing_ids = set(json_data.keys())\n",
    "\n",
    "    # Step 2: .txt file\n",
    "    with open(txt_path, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    blocks = re.split(r\"=== Case (\\d{4})[^\\n]*===\", text) # keep IDs\n",
    "    new_cases = {}\n",
    "\n",
    "    for i in range(1, len(blocks), 2):\n",
    "        qid = blocks[i].strip()\n",
    "        print(qid)\n",
    "        case_text = blocks[i+1]\n",
    "\n",
    "        if qid in existing_ids:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        pro_match = re.search(r\"Pro: ([A-D])\", case_text)\n",
    "        con_match = re.search(r\"Con: ([A-D])\", case_text)\n",
    "        consensus_match = re.search(r\"‚úÖ Consensus: ([A-D])\", case_text)\n",
    "        # Extract the Answer\n",
    "        if not consensus_match:\n",
    "            fallback_match = re.search(r\"Answer:\\s+\\*+\\s*([A-Z])\", case_text)\n",
    "            if not fallback_match:\n",
    "                fallback_match = re.search(r\"Answer:\\s*([A-Z])\", case_text)  # ÊúÄÂêéÂÖúÂ∫ï\n",
    "            consensus_match = fallback_match\n",
    "        \n",
    "        gt_match = re.search(r\"üß™ Ground Truth: ([A-D])\", case_text)\n",
    "\n",
    "        if not all([pro_match, con_match, consensus_match, gt_match]):\n",
    "            print(f\"‚ö†Ô∏è Skipping malformed case {qid}\")\n",
    "            continue\n",
    "\n",
    "        new_cases[qid] = {\n",
    "            \"question\": \"\",\n",
    "            \"pro_answer\": pro_match.group(1),\n",
    "            \"con_answer\": con_match.group(1),\n",
    "            \"consensus_answer\": consensus_match.group(1),\n",
    "            \"ground_truth\": gt_match.group(1),\n",
    "        }\n",
    "\n",
    "    # Step 3: Merge File \n",
    "    merged_data = {**json_data, **new_cases}\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(merged_data, f, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Merged {len(new_cases)} new cases into {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0050\n",
      "0051\n",
      "0052\n",
      "0053\n",
      "0054\n",
      "0055\n",
      "0056\n",
      "0057\n",
      "0058\n",
      "0059\n",
      "0060\n",
      "0061\n",
      "0062\n",
      "0063\n",
      "0064\n",
      "0065\n",
      "0066\n",
      "0067\n",
      "0068\n",
      "0069\n",
      "0070\n",
      "0071\n",
      "0072\n",
      "0073\n",
      "0074\n",
      "0075\n",
      "0076\n",
      "0077\n",
      "0078\n",
      "0079\n",
      "0080\n",
      "0081\n",
      "0082\n",
      "0083\n",
      "0084\n",
      "0085\n",
      "0086\n",
      "0087\n",
      "0088\n",
      "0089\n",
      "0090\n",
      "0091\n",
      "0092\n",
      "0093\n",
      "0094\n",
      "0095\n",
      "0096\n",
      "0097\n",
      "0098\n",
      "0099\n",
      "0100\n",
      "0101\n",
      "0102\n",
      "0103\n",
      "0104\n",
      "0105\n",
      "0106\n",
      "0107\n",
      "0108\n",
      "0109\n",
      "0110\n",
      "0111\n",
      "0112\n",
      "0113\n",
      "0114\n",
      "0115\n",
      "0116\n",
      "0117\n",
      "0118\n",
      "0119\n",
      "0120\n",
      "0121\n",
      "0122\n",
      "0123\n",
      "0124\n",
      "0125\n",
      "0126\n",
      "0127\n",
      "0128\n",
      "0129\n",
      "0130\n",
      "0131\n",
      "0132\n",
      "0133\n",
      "0134\n",
      "0135\n",
      "0136\n",
      "0137\n",
      "0138\n",
      "0139\n",
      "0140\n",
      "0141\n",
      "0142\n",
      "0143\n",
      "0144\n",
      "0145\n",
      "0146\n",
      "0147\n",
      "0148\n",
      "0149\n",
      "0150\n",
      "0151\n",
      "0152\n",
      "0153\n",
      "0154\n",
      "0155\n",
      "0156\n",
      "0157\n",
      "0158\n",
      "0159\n",
      "0160\n",
      "0161\n",
      "0162\n",
      "0163\n",
      "0164\n",
      "0165\n",
      "0166\n",
      "0167\n",
      "0168\n",
      "0169\n",
      "0170\n",
      "0171\n",
      "0172\n",
      "0173\n",
      "0174\n",
      "0175\n",
      "0176\n",
      "0177\n",
      "0178\n",
      "0179\n",
      "0180\n",
      "0181\n",
      "0182\n",
      "0183\n",
      "0184\n",
      "0185\n",
      "0186\n",
      "0187\n",
      "0188\n",
      "0189\n",
      "0190\n",
      "0191\n",
      "0192\n",
      "0193\n",
      "0194\n",
      "0195\n",
      "0196\n",
      "0197\n",
      "0198\n",
      "0199\n",
      "0200\n",
      "0201\n",
      "0202\n",
      "0203\n",
      "0204\n",
      "0205\n",
      "0206\n",
      "0207\n",
      "0208\n",
      "0209\n",
      "0210\n",
      "0211\n",
      "0212\n",
      "0213\n",
      "0214\n",
      "0215\n",
      "0216\n",
      "0217\n",
      "0218\n",
      "0219\n",
      "0220\n",
      "0221\n",
      "0222\n",
      "0223\n",
      "0224\n",
      "0225\n",
      "0226\n",
      "0227\n",
      "0228\n",
      "0229\n",
      "0230\n",
      "0231\n",
      "0232\n",
      "0233\n",
      "0234\n",
      "0235\n",
      "0236\n",
      "0237\n",
      "0238\n",
      "0239\n",
      "0240\n",
      "0241\n",
      "0242\n",
      "0243\n",
      "0244\n",
      "0245\n",
      "0246\n",
      "0247\n",
      "0248\n",
      "0249\n",
      "0250\n",
      "0251\n",
      "0252\n",
      "0253\n",
      "0254\n",
      "0255\n",
      "0256\n",
      "0257\n",
      "0258\n",
      "0259\n",
      "0260\n",
      "0261\n",
      "0262\n",
      "0263\n",
      "0264\n",
      "0265\n",
      "0266\n",
      "0267\n",
      "0268\n",
      "0269\n",
      "0270\n",
      "0271\n",
      "0272\n",
      "0273\n",
      "0274\n",
      "0275\n",
      "0276\n",
      "0277\n",
      "0278\n",
      "0279\n",
      "0280\n",
      "0281\n",
      "0282\n",
      "0283\n",
      "0284\n",
      "0285\n",
      "0286\n",
      "0287\n",
      "0288\n",
      "0289\n",
      "0290\n",
      "0291\n",
      "0292\n",
      "0293\n",
      "0294\n",
      "0295\n",
      "0296\n",
      "0297\n",
      "0298\n",
      "0299\n",
      "0300\n",
      "0301\n",
      "0302\n",
      "0303\n",
      "0304\n",
      "0305\n",
      "0306\n",
      "0307\n",
      "0308\n",
      "0309\n",
      "0310\n",
      "0311\n",
      "0312\n",
      "0313\n",
      "0314\n",
      "0000\n",
      "0001\n",
      "0002\n",
      "0003\n",
      "0004\n",
      "0005\n",
      "0006\n",
      "0007\n",
      "0008\n",
      "0009\n",
      "0010\n",
      "0011\n",
      "0012\n",
      "0013\n",
      "0014\n",
      "0015\n",
      "0016\n",
      "0017\n",
      "0018\n",
      "0019\n",
      "0020\n",
      "0021\n",
      "0022\n",
      "0023\n",
      "0024\n",
      "0025\n",
      "0026\n",
      "0027\n",
      "0028\n",
      "0029\n",
      "0030\n",
      "0031\n",
      "0032\n",
      "0033\n",
      "0034\n",
      "0035\n",
      "0036\n",
      "0037\n",
      "0038\n",
      "0039\n",
      "0040\n",
      "0041\n",
      "0042\n",
      "0043\n",
      "0044\n",
      "0045\n",
      "0046\n",
      "0047\n",
      "0048\n",
      "0049\n",
      "‚úÖ Merged 275 new cases into output_0_315.json\n"
     ]
    }
   ],
   "source": [
    "merge_txt_cases_to_json(\n",
    "    txt_path=\"output_merged.txt\",          \n",
    "    json_path=\"refine_con.json\",    \n",
    "    output_path=\"output_0_315.json\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether you miss some output after merging the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Missing IDs (0):\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def find_missing_ids(json_path, start=0, end=314):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    existing_ids = set(data.keys())\n",
    "    expected_ids = {f\"{i:04d}\" for i in range(start, end + 1)}\n",
    "\n",
    "    missing_ids = sorted(expected_ids - existing_ids)\n",
    "\n",
    "    print(f\"üîç Missing IDs ({len(missing_ids)}):\")\n",
    "    for mid in missing_ids:\n",
    "        print(mid)\n",
    "\n",
    "\n",
    "find_missing_ids(\"output_0_315.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
